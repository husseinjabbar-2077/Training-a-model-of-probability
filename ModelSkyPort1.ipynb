{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 images belonging to 50 classes.\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 17s 1s/step - loss: 4.2498 - accuracy: 0.0685\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 16s 970ms/step - loss: 3.7874 - accuracy: 0.0827\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 15s 933ms/step - loss: 3.7329 - accuracy: 0.1129\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 17s 1s/step - loss: 3.7127 - accuracy: 0.1190\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 16s 1s/step - loss: 3.7028 - accuracy: 0.1169\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 16s 1s/step - loss: 3.6574 - accuracy: 0.1270\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 16s 994ms/step - loss: 3.6636 - accuracy: 0.1149\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 15s 889ms/step - loss: 3.5967 - accuracy: 0.1210\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 16s 1s/step - loss: 3.5294 - accuracy: 0.1190\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 16s 999ms/step - loss: 3.5047 - accuracy: 0.1129\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 15s 930ms/step - loss: 3.4731 - accuracy: 0.1270\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 16s 968ms/step - loss: 3.4152 - accuracy: 0.1351\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 16s 1000ms/step - loss: 3.3954 - accuracy: 0.1089\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 17s 1s/step - loss: 3.3606 - accuracy: 0.1371\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 17s 1s/step - loss: 3.3290 - accuracy: 0.1411\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 17s 1s/step - loss: 3.2339 - accuracy: 0.1532\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 15s 975ms/step - loss: 3.2845 - accuracy: 0.1552\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 16s 1s/step - loss: 3.1545 - accuracy: 0.1653\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 16s 999ms/step - loss: 3.1801 - accuracy: 0.1573\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 17s 1s/step - loss: 3.2080 - accuracy: 0.1754\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# تحديد هيكل النموذج\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.7))  # تقليل احتمال الإفراط في التدريب\n",
    "num_classes = 50  # قم بتعيين هذا العدد بناءً على عدد الفئات في بياناتك\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# تكوين مولد البيانات مع تعزيز البيانات\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'training_data',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# تدريب النموذج\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_generator, epochs=20)  # زيادة عدد الدورات\n",
    "\n",
    "# حفظ النموذج\n",
    "model.save('SkyPortH1.h5')\n",
    "\n",
    "# تحميل النموذج واستخدامه للتصنيف\n",
    "loaded_model = tf.keras.models.load_model('SkyPortH1.h5')\n",
    "\n",
    "# استخدام النموذج لتصنيف صور جديدة\n",
    "# قم بتحميل الصور الجديدة واستخدام loaded_model.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "أعلى الاحتمالات:\n",
      "امراة: 0.1293\n",
      "سمراء البشرة: 0.0736\n",
      "تبكي: 0.0620\n",
      "رجل: 0.0615\n",
      "كبيرة في السن: 0.0579\n",
      "امراة سمراء البشرة تبكي رجل كبيرة في السن \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "# قم بتحميل النموذج\n",
    "loaded_model = tf.keras.models.load_model('SkyPortH1.h5')\n",
    "\n",
    "# قم بتحميل صورة جديدة للتصنيف\n",
    "image_path = 'a.jpg'  # استبدل هذا بمسار الصورة الجديدة\n",
    "\n",
    "# قم بتحميل وتحويل الصورة لتكون متوافقة مع النموذج\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img / 255.0  # قد تحتاج لإجراء تحسينات إضافية هنا بناءً على كيفية تنسيق بيانات التدريب\n",
    "\n",
    "# استخدم النموذج للتصنيف\n",
    "predictions = loaded_model.predict(img)\n",
    "\n",
    "# احصل على التصنيف النهائي\n",
    "class_index = np.argmax(predictions)\n",
    "\n",
    "# احصل على اسم التصنيف\n",
    "class_labels = train_generator.class_indices  # افترض أن train_generator هو مولد البيانات الذي تم استخدامه في التدريب\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "predicted_class = class_labels[class_index]\n",
    "\n",
    "# قم بقراءة أسماء التصنيفات الفرعية من مجلد الفهارس\n",
    "class_labels_subfolders = os.listdir('training_data')  # استبدل 'path/to/subdirectories' بمسار مجلد الفهارس\n",
    "\n",
    "# احصل على احتمالات التصنيفات الفرعية\n",
    "class_probabilities = predictions[0]\n",
    "\n",
    "# القيمة الصغيرة جدًا\n",
    "probability = 7.079136412357911e-05\n",
    "\n",
    "# احصل على الفئات الأعلى احتمالًا\n",
    "top_n = 5  # عدد الفئات الأعلى احتمالًا التي ترغب في طباعتها\n",
    "top_indices = np.argsort(predictions[0])[::-1][:top_n]\n",
    "\n",
    "# احصل على أسماء الفئات المقابلة\n",
    "top_classes = [class_labels_subfolders[i] for i in top_indices]\n",
    "\n",
    "# احصل على الأحتمالات المقابلة\n",
    "top_probabilities = [class_probabilities[i] for i in top_indices]\n",
    "\n",
    "# طباعة الفئات والأحتمالات\n",
    "print(\"أعلى الاحتمالات:\")\n",
    "namePrint = ''\n",
    "for i in range(top_n):\n",
    "    namePrint += top_classes[i] + ' '\n",
    "    print(f\"{top_classes[i]}: {top_probabilities[i]:.4f}\")\n",
    "\n",
    "print(namePrint)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
